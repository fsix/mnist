<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>MNIST by fsix</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>MNIST</h1>
        <p>Tips and Tricks for Cracking ML&#39;s Favorite Image Dataset</p>

        <p class="view"><a href="https://github.com/fsix/mnist">View the Project on GitHub <small>fsix/mnist</small></a></p>


        <ul>
          <li><a href="https://github.com/fsix/mnist/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/fsix/mnist/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/fsix/mnist">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h1>

<p>MNIST is a dataset of handwritten digits published in the 1990s, MNIST is perhaps one of the most iconic exercises for beginning Machine Learning, and a milestone in using computers to structurally analyse images. This guide will serve as an exploration of the MNIST dataset, beginning with simple methods and eventually reaching methods that will reach 99% accuracy.</p>

<h2>
<a id="preprocessing-techniques" class="anchor" href="#preprocessing-techniques" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Preprocessing Techniques</h2>

<h3>
<a id="deskewing" class="anchor" href="#deskewing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deskewing</h3>

<p>Deskewing images involves offsetting and skewing images so their center of masses coincide with the center of the image and such that the x and y covariance of the pixel intensities is 0. By reversing the proposed affine transformation, we essentially "standardize" the images, making it much easier for the ML algorithm to distinguish between images.</p>

<p><a href="Deskewing.html">Check out the Jupyter Notebook here</a></p>

<h2>
<a id="optimizing-hyperparameters" class="anchor" href="#optimizing-hyperparameters" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optimizing Hyperparameters</h2>

<h3>
<a id="linegrid-search" class="anchor" href="#linegrid-search" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Line/Grid Search</h3>

<h3>
<a id="bayesian-optimization" class="anchor" href="#bayesian-optimization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bayesian Optimization</h3>

<p>This was too complicated to explain in a single iPython notebook, so we'll release this later.</p>

<h2>
<a id="adverserial-training" class="anchor" href="#adverserial-training" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Adverserial Training</h2>

<h3>
<a id="perturbing" class="anchor" href="#perturbing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Perturbing</h3>

<p>Perturbation is the technique of generating "jittered" images from our original training dataset. In particular, we found that adding random noise, random rotations, skews, and elastic distortions help generalize our dataset against adversarial images.</p>

<p>This technique is a specialized form of training for "adversarial images", when the testing metric is designed to challenge and perform the worst on overfit and nongeneralized models. </p>

<p><a href="Perturbing.html">Check out the Jupyter Notebook here</a></p>

<h2>
<a id="guiding-approximations" class="anchor" href="#guiding-approximations" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Guiding Approximations</h2>

<h3>
<a id="momentum-and-annealing-for-sgd" class="anchor" href="#momentum-and-annealing-for-sgd" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Momentum and Annealing for SGD</h3>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/fsix">fsix</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
